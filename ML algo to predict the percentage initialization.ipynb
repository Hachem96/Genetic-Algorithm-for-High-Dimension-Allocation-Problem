{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant librarie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import nan\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_functions_G2</th>\n",
       "      <th>max_connections</th>\n",
       "      <th>min_connections</th>\n",
       "      <th>mean_connections</th>\n",
       "      <th>variance_connections</th>\n",
       "      <th>mean_val_connect</th>\n",
       "      <th>std_val_connect</th>\n",
       "      <th>SAS_RCSL</th>\n",
       "      <th>PS_PAS</th>\n",
       "      <th>PS_SAS</th>\n",
       "      <th>PS_RCSL</th>\n",
       "      <th>DAS_PAS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_study</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F2000_C100_X0_0</th>\n",
       "      <td>539</td>\n",
       "      <td>322</td>\n",
       "      <td>64</td>\n",
       "      <td>162.523191</td>\n",
       "      <td>31.995076</td>\n",
       "      <td>892.359926</td>\n",
       "      <td>178.231743</td>\n",
       "      <td>21837</td>\n",
       "      <td>42806</td>\n",
       "      <td>41149</td>\n",
       "      <td>0</td>\n",
       "      <td>23327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2000_C100_X0_1</th>\n",
       "      <td>552</td>\n",
       "      <td>306</td>\n",
       "      <td>55</td>\n",
       "      <td>162.884058</td>\n",
       "      <td>30.502524</td>\n",
       "      <td>894.579710</td>\n",
       "      <td>170.594639</td>\n",
       "      <td>22672</td>\n",
       "      <td>42044</td>\n",
       "      <td>40049</td>\n",
       "      <td>0</td>\n",
       "      <td>22546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2000_C100_X0_2</th>\n",
       "      <td>529</td>\n",
       "      <td>317</td>\n",
       "      <td>44</td>\n",
       "      <td>157.903592</td>\n",
       "      <td>35.170098</td>\n",
       "      <td>868.816635</td>\n",
       "      <td>198.434141</td>\n",
       "      <td>19052</td>\n",
       "      <td>38128</td>\n",
       "      <td>34617</td>\n",
       "      <td>0</td>\n",
       "      <td>21565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2000_C100_X0_3</th>\n",
       "      <td>549</td>\n",
       "      <td>302</td>\n",
       "      <td>49</td>\n",
       "      <td>157.783242</td>\n",
       "      <td>32.691580</td>\n",
       "      <td>868.520947</td>\n",
       "      <td>185.294720</td>\n",
       "      <td>22412</td>\n",
       "      <td>35674</td>\n",
       "      <td>36916</td>\n",
       "      <td>0</td>\n",
       "      <td>20543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2000_C100_X0_4</th>\n",
       "      <td>567</td>\n",
       "      <td>299</td>\n",
       "      <td>29</td>\n",
       "      <td>158.922399</td>\n",
       "      <td>33.107080</td>\n",
       "      <td>875.190476</td>\n",
       "      <td>187.357934</td>\n",
       "      <td>22899</td>\n",
       "      <td>39454</td>\n",
       "      <td>36779</td>\n",
       "      <td>0</td>\n",
       "      <td>23380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nb_functions_G2  max_connections  min_connections  \\\n",
       "case_study                                                           \n",
       "F2000_C100_X0_0              539              322               64   \n",
       "F2000_C100_X0_1              552              306               55   \n",
       "F2000_C100_X0_2              529              317               44   \n",
       "F2000_C100_X0_3              549              302               49   \n",
       "F2000_C100_X0_4              567              299               29   \n",
       "\n",
       "                 mean_connections  variance_connections  mean_val_connect  \\\n",
       "case_study                                                                  \n",
       "F2000_C100_X0_0        162.523191             31.995076        892.359926   \n",
       "F2000_C100_X0_1        162.884058             30.502524        894.579710   \n",
       "F2000_C100_X0_2        157.903592             35.170098        868.816635   \n",
       "F2000_C100_X0_3        157.783242             32.691580        868.520947   \n",
       "F2000_C100_X0_4        158.922399             33.107080        875.190476   \n",
       "\n",
       "                 std_val_connect  SAS_RCSL  PS_PAS  PS_SAS  PS_RCSL  DAS_PAS  \n",
       "case_study                                                                    \n",
       "F2000_C100_X0_0       178.231743     21837   42806   41149        0    23327  \n",
       "F2000_C100_X0_1       170.594639     22672   42044   40049        0    22546  \n",
       "F2000_C100_X0_2       198.434141     19052   38128   34617        0    21565  \n",
       "F2000_C100_X0_3       185.294720     22412   35674   36916        0    20543  \n",
       "F2000_C100_X0_4       187.357934     22899   39454   36779        0    23380  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:\\\\Users\\\\AH262855\\\\Desktop\\\\Nouveau dossier\\\\Data_ML\\\\perc_initialization\\\\features_train_data.csv\"\n",
    "data = pd.read_csv(data_path,index_col=0,encoding = \"ISO-8859-1\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the output file\n",
    "We have 5 intervals and the output of a study case is one of the means of these 5 intervals.\n",
    "<br> These values are replaced by an integer between 0 and 4. Each integer represents one classe (one value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes_path = \"C:\\\\Users\\\\AH262855\\\\Desktop\\\\Nouveau dossier\\\\Data_ML\\\\perc_initialization\\\\best_perc_ini.csv\"\n",
    "output = pd.read_csv(sizes_path,index_col=0,encoding = \"ISO-8859-1\")\n",
    "perc_ini = [0.05,0.15,0.25,0.35,0.45]\n",
    "temp = np.zeros((len(output),len(perc_ini)))\n",
    "y = np.zeros(len(output))\n",
    "for i in range(0,len(output)):\n",
    "    a = np.argwhere(output.values[i]==perc_ini)\n",
    "    temp[i,a[0]] = 1\n",
    "    y[i] = a[0] + 1\n",
    "#y = temp\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of samples in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.032  , 0.1265 , 0.361  , 0.34575, 0.13475])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [1,2,3,4,5]\n",
    "counts = np.zeros(len(classes ))\n",
    "for i in range(0,len(classes )):\n",
    "    counts[i] = len(np.argwhere(y==classes [i]))\n",
    "counts /= len(y)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_functions_G2        -0.391405\n",
       "max_connections         0.150528\n",
       "min_connections         0.115390\n",
       "mean_connections        0.133920\n",
       "variance_connections    0.194717\n",
       "mean_val_connect        0.133896\n",
       "std_val_connect         0.194706\n",
       "SAS_RCSL               -0.040568\n",
       "PS_PAS                 -0.017904\n",
       "PS_SAS                 -0.040431\n",
       "PS_RCSL                -0.217614\n",
       "DAS_PAS                -0.019785\n",
       "y                       1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df_1 = pd.DataFrame(data= output)\n",
    "df = data.copy()\n",
    "df['y'] =  df_1\n",
    "#plt.figure(figsize=(5,5))\n",
    "#sns.heatmap(df.corr())\n",
    "corr = df.corr()\n",
    "temp = corr['y']\n",
    "temp\n",
    "#temp.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Split the data\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, y, test_size=0.1,random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" normalization of the data\"\n",
    "mean = X_train.mean(axis=0)\n",
    "stdev = X_train.std(axis=0)\n",
    "X_train_normalize = (X_train - mean)/stdev\n",
    "X_val_normalize =  (X_val - mean)/stdev\n",
    "#X_test_normalize =  (X_test - mean)/stdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  7  4  1  1]\n",
      " [ 1 11 23 10  6]\n",
      " [ 1 12 91 34  6]\n",
      " [ 0  2 42 83 11]\n",
      " [ 0  0  5 27 22]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val,y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.4, 'eta': 0.3, 'gamma': 0, 'lambda': 0.7999999999999999, 'max_depth': 4}\n",
      "train_accuracy:  0.88\n",
      "val_accuracy:  0.5175\n",
      "confusion matrix of validation data\n",
      "[[ 0  7  4  1  1]\n",
      " [ 1 11 23 10  6]\n",
      " [ 1 12 91 34  6]\n",
      " [ 0  2 42 83 11]\n",
      " [ 0  0  5 27 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.05       0.00      0.00      0.00        13\n",
      "        0.15       0.34      0.22      0.27        51\n",
      "        0.25       0.55      0.63      0.59       144\n",
      "        0.35       0.54      0.60      0.57       138\n",
      "        0.45       0.48      0.41      0.44        54\n",
      "\n",
      "    accuracy                           0.52       400\n",
      "   macro avg       0.38      0.37      0.37       400\n",
      "weighted avg       0.49      0.52      0.50       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.21568627, 0.63194444, 0.60144928, 0.40740741])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = xgb.XGBClassifier(objective= 'multi:softmax', num_class =5)\n",
    "param = {\n",
    "    'max_depth': [4],\n",
    "    'eta': [0.3],#np.arange(0.2,1,0.1), \n",
    "    'gamma': [0], \n",
    "    'lambda':np.arange(0.5,1,0.1),\n",
    "    'alpha': np.arange(0,0.5,0.1), }\n",
    "best_xgb = GridSearchCV(estimator=XGB,param_grid=param,n_jobs = 8,cv = 5)\n",
    "best_xgb.fit(X_train_normalize, y_train)\n",
    "print(best_xgb.best_params_)\n",
    "y_pred_train = best_xgb.predict(X_train_normalize)\n",
    "print(\"train_accuracy: \", accuracy_score(y_train,y_pred_train))\n",
    "y_pred_val = best_xgb.predict(X_val_normalize)\n",
    "print(\"val_accuracy: \",accuracy_score(y_val,y_pred_val))\n",
    "print(\"confusion matrix of validation data\")\n",
    "print(confusion_matrix(y_val,y_pred_val))\n",
    "target_names = ['0.05','0.15', '0.25', '0.35', '0.45']\n",
    "print(classification_report(y_val, y_pred_val, target_names=target_names))\n",
    "#print(confusion_matrix(y_train,y_pred_train))\n",
    "matrix = confusion_matrix(y_val,y_pred_val)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = data.columns) \n",
    "columns = data.columns\n",
    "for column in  columns:\n",
    "    maximum = max( data[column])\n",
    "    minimum = min(data[column])\n",
    "    df[column] = np.random.randint(minimum,maximum,1000)\n",
    "  \n",
    "add_random_data = data.copy()\n",
    "add_random_data = add_random_data.append(df, ignore_index=False)\n",
    "Y = np.random.choice(classes, 1000, p =counts)\n",
    "y_random = y.copy()\n",
    "y_random  = np.append(y_random ,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Split the data\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(add_random_data,y_random ,test_size=0.1,random_state=5,stratify=y_random )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" normalization of the data\"\n",
    "mean = X_train.mean(axis=0)\n",
    "stdev = X_train.std(axis=0)\n",
    "X_train_normalize = (X_train - mean)/stdev\n",
    "X_val_normalize =  (X_val - mean)/stdev\n",
    "#X_test_normalize =  (X_test - mean)/stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.4, 'eta': 0.3, 'gamma': 0, 'lambda': 0.8, 'max_depth': 4}\n",
      "train_accuracy:  0.8211111111111111\n",
      "val_accuracy:  0.488\n",
      "confusion matrix of validation data\n",
      "[[  1   1   7   5   2]\n",
      " [  1   4  40  16   1]\n",
      " [  0   7 121  46   7]\n",
      " [  0   6  60  95  12]\n",
      " [  0   3  14  28  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.05       0.50      0.06      0.11        16\n",
      "        0.15       0.19      0.06      0.10        62\n",
      "        0.25       0.50      0.67      0.57       181\n",
      "        0.35       0.50      0.55      0.52       173\n",
      "        0.45       0.51      0.34      0.41        68\n",
      "\n",
      "    accuracy                           0.49       500\n",
      "   macro avg       0.44      0.34      0.34       500\n",
      "weighted avg       0.46      0.49      0.46       500\n",
      "\n",
      "[[ 122    5   14    5    1]\n",
      " [   1  349  152   48    6]\n",
      " [   0   12 1427  167   17]\n",
      " [   0    5  216 1304   35]\n",
      " [   0    5   26   90  493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.05       0.99      0.83      0.90       147\n",
      "        0.15       0.93      0.63      0.75       556\n",
      "        0.25       0.78      0.88      0.83      1623\n",
      "        0.35       0.81      0.84      0.82      1560\n",
      "        0.45       0.89      0.80      0.85       614\n",
      "\n",
      "    accuracy                           0.82      4500\n",
      "   macro avg       0.88      0.80      0.83      4500\n",
      "weighted avg       0.83      0.82      0.82      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB = xgb.XGBClassifier(objective= 'multi:softmax',num_class =5)\n",
    "param = {\n",
    "    'max_depth': [4],#np.arange(3,6,1),\n",
    "    'eta': [0.3],#np.arange(0.2,0.5,0.1), \n",
    "    'gamma': [0], \n",
    "    'lambda':[0.8],#np.arange(0.7,1,0.1),\n",
    "    'alpha': [0.4],}#np.arange(0,0.3,0.1), }\n",
    "best_xgb = GridSearchCV(estimator=XGB,param_grid=param,n_jobs = 8,cv = 5)\n",
    "best_xgb.fit(X_train_normalize, y_train)\n",
    "print(best_xgb.best_params_)\n",
    "y_pred_train = best_xgb.predict(X_train_normalize)\n",
    "print(\"train_accuracy: \", accuracy_score(y_train,y_pred_train))\n",
    "y_pred_val = best_xgb.predict(X_val_normalize)\n",
    "print(\"val_accuracy: \",accuracy_score(y_val,y_pred_val))\n",
    "print(\"confusion matrix of validation data\")\n",
    "print(confusion_matrix(y_val,y_pred_val))\n",
    "target_names = ['0.05','0.15', '0.25', '0.35', '0.45']\n",
    "print(classification_report(y_val, y_pred_val, target_names=target_names))\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
